{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 8 — \"Hessians, Curvature & Second-Order Optimization\"\n",
        "\n",
        "Gradients tell you which way is downhill; Hessians describe how that downhill path bends. Second-order information reshapes the loss landscape into something easier to navigate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Core Intuition\n",
        "\n",
        "- Gradient = slope; Hessian = how the slope curves.\n",
        "- Knowing curvature means you can slow down in steep directions and speed up in flat ones.\n",
        "- Second-order methods use this curvature map to avoid zigzags.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Curvature Concepts\n",
        "\n",
        "| Curvature type | Hessian sign | Behavior |\n",
        "| --- | --- | --- |\n",
        "| Positive | > 0 | Bowl: one global min. |\n",
        "| Negative | < 0 | Concave: you're on a peak. |\n",
        "| Mixed | varies | Saddles: up in one direction, down in another. |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Hessian Matrix\n",
        "\n",
        "- `H = ∇²L(θ)` collects all second partial derivatives.\n",
        "- Eigenvectors of `H` give directions; eigenvalues give curvature strength.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Python Implementation — Hessian & Newton Steps\n",
        "\n",
        "`days/day08/code/hessian_demo.py` computes loss, gradient, Hessian, and Newton updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at w: 18.75\n",
            "Gradient at w: [13.4 -2. ]\n",
            "Hessian:\n",
            " [[6.  0.8]\n",
            " [0.8 2. ]]\n",
            "Newton step: [ 0.00000000e+00 -2.22044605e-16]\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def find_repo_root(marker: str = \"days\") -> Path:\n",
        "    path = Path.cwd()\n",
        "    while path != path.parent:\n",
        "        if (path / marker).exists():\n",
        "            return path\n",
        "        path = path.parent\n",
        "    raise RuntimeError(\"Run this notebook from inside the repository tree.\")\n",
        "\n",
        "REPO_ROOT = find_repo_root()\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.append(str(REPO_ROOT))\n",
        "\n",
        "from days.day08.code.hessian_demo import grad, hessian, loss, newton_step\n",
        "\n",
        "w = np.array([2.5, -2.0])\n",
        "print('Loss at w:', loss(w))\n",
        "print('Gradient at w:', grad(w))\n",
        "print('Hessian:\\n', hessian(None))\n",
        "print('Newton step:', newton_step(w))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualization — Newton vs Gradient Descent\n",
        "\n",
        "`days/day08/code/visualizations.py` renders the surface and an animation comparing GD to Newton."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set RUN_ANIMATIONS = True to regenerate Day 8 figures in days/day08/outputs/.\n"
          ]
        }
      ],
      "source": [
        "from days.day08.code.visualizations import render_surface, anim_newton_vs_gd\n",
        "\n",
        "RUN_ANIMATIONS = False\n",
        "\n",
        "if RUN_ANIMATIONS:\n",
        "    surf = render_surface('Quadratic Loss Surface', '00_loss_surface.png')\n",
        "    gif = anim_newton_vs_gd()\n",
        "    print('Saved assets:', surf, gif)\n",
        "else:\n",
        "    print('Set RUN_ANIMATIONS = True to regenerate Day 8 figures in days/day08/outputs/.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Why Newton’s Method Is Rare in DL\n",
        "\n",
        "- Hessian is huge (millions × millions).\n",
        "- Computing and inverting it is expensive.\n",
        "- Stochasticity makes Hessian noisy.\n",
        "\n",
        "Yet modern optimizers mimic second-order ideas (Adam, RMSProp, natural gradient, K-FAC)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Mini Exercises\n",
        "\n",
        "1. Reduce the learning rate to see GD converge more gracefully on curved valleys.\n",
        "2. Inject noise into gradients and observe how Newton jumps become unstable.\n",
        "3. Approximate Hessian eigenvalues numerically using finite differences.\n",
        "4. Compare Adam steps to Newton’s step on this quadratic (diagonal approximation).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Key Takeaways\n",
        "\n",
        "| Concept | Meaning |\n",
        "| --- | --- |\n",
        "| Hessian | Describes curvature; second derivatives all in one matrix. |\n",
        "| Eigenvalues | Curvature magnitude/direction. |\n",
        "| Newton step | Rescales gradients by curvature; no zigzag on quadratics. |\n",
        "| Second-order optimizers | Adam/RMSProp approximate Hessian inverses cheaply. |\n",
        "| Practicality | Full Hessians are infeasible for deep nets; approximations rule. |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
