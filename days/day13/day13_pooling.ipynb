{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 13 — \"Pooling, Downsampling & Hierarchical Feature Extraction\"\n",
        "\n",
        "Pooling lets CNNs zoom out: compressing details while preserving meaning so deeper layers capture shapes, parts, and objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Core Intuition\n",
        "\n",
        "- Pooling mimics stepping back from an image: details → shapes → scenes.\n",
        "- Downsampling builds hierarchical, multi-scale features (pixels → edges → textures → parts → objects)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Why Pooling is Needed\n",
        "\n",
        "- Convolution alone lacks invariance.\n",
        "- Pooling selects salient features, compresses maps, enlarges receptive fields, reduces compute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Max Pooling\n",
        "\n",
        "`maxpool(x) = max(x_1, ..., x_n)` within a window. Picks the strongest activation, giving shift invariance and sparsity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Average Pooling & GAP\n",
        "\n",
        "- `avgpool(x) = (1/n)∑x_i` keeps smooth context.\n",
        "- Global Average Pooling (GAP) replaces FC heads, reduces parameters, improves generalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Strided Convolution\n",
        "\n",
        "Learnable downsampling that lets the model decide which info to retain; common replacement for rigid pooling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Python Demo — Pooling & Strided Convolution\n",
        "\n",
        "`days/day13/code/pooling.py` implements the helpers below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b42b2c90",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:\n",
            " [[1 3 2 8]\n",
            " [4 6 5 2]\n",
            " [7 1 0 3]\n",
            " [2 9 4 1]]\n",
            "MaxPool 2x2:\n",
            " [[6. 8.]\n",
            " [9. 4.]]\n",
            "AvgPool 2x2:\n",
            " [[3.5  4.25]\n",
            " [4.75 2.  ]]\n",
            "Global Avg Pool: 3.625\n",
            "Strided conv (stride=2):\n",
            " [[ 0. -9.]\n",
            " [13. -6.]]\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def find_repo_root(marker: str = \"days\") -> Path:\n",
        "    path = Path.cwd()\n",
        "    while path != path.parent:\n",
        "        if (path / marker).exists():\n",
        "            return path\n",
        "        path = path.parent\n",
        "    raise RuntimeError(\"Run this notebook from inside the repository tree.\")\n",
        "\n",
        "REPO_ROOT = find_repo_root()\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.append(str(REPO_ROOT))\n",
        "\n",
        "from days.day13.code.pooling import pool2d, global_avg_pool, strided_conv2d\n",
        "\n",
        "img = np.array([[1,3,2,8],[4,6,5,2],[7,1,0,3],[2,9,4,1]])\n",
        "filt = np.array([[1,-1],[-1,1]])\n",
        "print(\"Original:\\n\", img)\n",
        "print(\"MaxPool 2x2:\\n\", pool2d(img, mode='max'))\n",
        "print(\"AvgPool 2x2:\\n\", pool2d(img, mode='avg'))\n",
        "print(\"Global Avg Pool:\", global_avg_pool(img))\n",
        "print(\"Strided conv (stride=2):\\n\", strided_conv2d(img, filt, stride=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualization — Pooling Movement\n",
        "\n",
        "`days/day13/code/visualizations.py` plots pooling results and animates a sliding max-pool window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set RUN_ANIMATIONS = True to regenerate Day 13 figures in days/day13/outputs/.\n"
          ]
        }
      ],
      "source": [
        "from days.day13.code.visualizations import plot_pooling_example, anim_sliding_maxpool\n",
        "\n",
        "RUN_ANIMATIONS = False\n",
        "\n",
        "if RUN_ANIMATIONS:\n",
        "    plot_path = plot_pooling_example()\n",
        "    gif_path = anim_sliding_maxpool()\n",
        "    print('Saved assets →', plot_path, gif_path)\n",
        "else:\n",
        "    print('Set RUN_ANIMATIONS = True to regenerate Day 13 figures in days/day13/outputs/.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Hierarchical Feature Extraction\n",
        "\n",
        "Pooling expands receptive fields so deeper layers capture textures, parts, and objects—mirroring human perception from pixels to scenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Pooling vs Strided Convolution\n",
        "\n",
        "| Property | Pooling | Strided Conv |\n",
        "| --- | --- | --- |\n",
        "| Learnable | No | Yes |\n",
        "| Invariance | Strong (max) | Moderate |\n",
        "| Sharpness | High (max) | Depends on learned filters |\n",
        "| Modern usage | Declining | Increasing |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Mini Exercises\n",
        "\n",
        "1. Implement max pool manually and compare to torch.nn.MaxPool2d.\n",
        "2. Swap max pool for average pool in a CNN; observe accuracy.\n",
        "3. Replace pooling with stride=2 conv; compare results.\n",
        "4. Visualize intermediate CNN feature maps (edges → textures → parts).\n",
        "5. Try GAP vs fully connected head on CIFAR-10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Key Takeaways\n",
        "\n",
        "| Point | Meaning |\n",
        "| --- | --- |\n",
        "| Pooling compresses & gains invariance | Less sensitive to small shifts. |\n",
        "| Max pooling highlights strong features | Edge detectors thrive. |\n",
        "| Average/GAP summarize context | Smooth, parameter-efficient heads. |\n",
        "| Strided conv learns what to keep | Flexible alternative to pooling. |\n",
        "| Hierarchical representations | CNNs zoom out layer by layer. |\n",
        "\n",
        "> Pooling lets networks zoom out—learning not just pixels, but patterns, parts, and objects."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
