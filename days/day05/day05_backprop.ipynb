{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 5 — \"How Learning Flows Backward\": Chain Rule & Backpropagation Intuition\n",
        "\n",
        "Backpropagation is the nervous system of a neural network: it sends responsibility backwards so each weight knows how to adjust."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Core Intuition\n",
        "\n",
        "- Think of layers as gears. Loss tweaks the final gear, and the chain rule tells us how earlier gears moved.\n",
        "- Backpropagation applies the chain rule efficiently through the entire stack.\n",
        "- Gradients quantify how much each neuron/weight contributed to the final error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mathematical Story — The Chain of Influence\n",
        "\n",
        "| Concept | Formula | Meaning |\n",
        "| --- | --- | --- |\n",
        "| Chain rule | `∂L/∂x = (∂L/∂y)(∂y/∂h₂)(∂h₂/∂h₁)(∂h₁/∂x)` | Influence ripples through each layer. |\n",
        "| Backprop recurrence | `δ_{l} = δ_{l+1} * ∂h_{l+1}/∂h_l` | Re-use gradients moving backward. |\n",
        "        | Responsibility | Each derivative indicates how strongly one stage affects the next. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Python Implementation — Chain Rule Demo\n",
        "\n",
        "`days/day05/code/backprop_demo.py` implements a tiny 2-layer network forward/backward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hidden activation h= 0.8336546070121552\n",
            "Output y= -0.6669236856097243\n",
            "Gradients (dL/dw1, dL/dw2, dL/dx)= (np.float64(0.2847480465272111), np.float64(-0.9728113065401505), np.float64(0.3416976558326533))\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def find_repo_root(marker: str = \"days\") -> Path:\n",
        "    path = Path.cwd()\n",
        "    while path != path.parent:\n",
        "        if (path / marker).exists():\n",
        "            return path\n",
        "        path = path.parent\n",
        "    raise RuntimeError(\"Run this notebook from inside the repository tree.\")\n",
        "\n",
        "REPO_ROOT = find_repo_root()\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.append(str(REPO_ROOT))\n",
        "\n",
        "from days.day05.code.backprop_demo import BackpropExample, forward, backward\n",
        "\n",
        "example = BackpropExample()\n",
        "h, y = forward(example.x, example.w1, example.w2)\n",
        "grads = backward(example.x, h, y, example.target, example.w1, example.w2)\n",
        "print(\"Hidden activation h=\", h)\n",
        "print(\"Output y=\", y)\n",
        "print(\"Gradients (dL/dw1, dL/dw2, dL/dx)=\", grads)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe how the single scalar error `(y - target)` travels backward through the chain, multiplying by local derivatives to produce gradients for each weight."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualization — Watching Gradients Flow\n",
        "\n",
        "`days/day05/code/visualizations.py` animates forward values vs. gradient magnitudes across a toy chain (tanh → square → identity)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set RUN_ANIMATIONS = True to regenerate GIFs in days/day05/outputs/.\n"
          ]
        }
      ],
      "source": [
        "from days.day05.code.visualizations import anim_backprop_chain\n",
        "\n",
        "RUN_ANIMATIONS = False\n",
        "\n",
        "if RUN_ANIMATIONS:\n",
        "    path = anim_backprop_chain()\n",
        "    print(f\"Saved backprop animation → {path}\")\n",
        "else:\n",
        "    print('Set RUN_ANIMATIONS = True to regenerate GIFs in days/day05/outputs/.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Deep Learning & CV Connections\n",
        "\n",
        "| Concept | What It Means in Practice |\n",
        "| --- | --- |\n",
        "| Chain rule | Every layer passes backward partial responsibility. |\n",
        "| Backprop | Efficient, vectorized chain rule for huge parameter counts. |\n",
        "| Gradient flow | Determines whether learning is stable (vanishing/exploding issues). |\n",
        "| Jacobians | Local linear maps of each layer; products of Jacobians describe gradient flow. |\n",
        "| Activations | ReLU keeps gradients alive; sigmoid/tanh may shrink them. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Mini Exercises\n",
        "\n",
        "1. Swap tanh for ReLU or sine in the demo and watch gradients change.\n",
        "2. Add more functions (e.g., `f4 = sin`) to the chain; plot gradient magnitudes.\n",
        "3. Modify the loss to `L = |output - target|` and derive derivatives manually.\n",
        "4. Extend the code to a 2-layer MLP (matrix weights) and verify gradients numerically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Key Takeaways\n",
        "\n",
        "| Concept | Meaning |\n",
        "| --- | --- |\n",
        "| Chain rule | Describes how changes ripple through composite functions. |\n",
        "| Backpropagation | Mechanized chain rule powering training. |\n",
        "| Gradient signal | Shows how much each neuron contributed to the loss. |\n",
        "| Activations | Influence whether gradients vanish or explode. |\n",
        "| Gradient flow | Healthy gradients = healthy learning. |\n",
        "\n",
        "> Backprop is how networks learn who to blame — and how to improve."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
