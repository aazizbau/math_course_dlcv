{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 28 — \"Foundation Models & Embeddings for EO (Prithvi, AlphaEarth, SatMAE)\"\n",
        "\n",
        "Foundation models learn Earth’s structure and dynamics. Embeddings compress multi-band, multi-temporal patches into semantic vectors you can reuse across tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [
          "python"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using repo root: /media/abdul-aziz/sdb7/masters_research/math_course_dlcv\n"
          ]
        }
      ],
      "source": [
        "# Ensure repo root is on sys.path for local imports\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "repo_root = Path.cwd()\n",
        "if not (repo_root / \"days\").exists():\n",
        "    for parent in Path.cwd().resolve().parents:\n",
        "        if (parent / \"days\").exists():\n",
        "            repo_root = parent\n",
        "            break\n",
        "\n",
        "sys.path.insert(0, str(repo_root))\n",
        "print(f\"Using repo root: {repo_root}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Core Intuition\n",
        "\n",
        "- Raw bands are letters; embeddings are the semantic meaning of Earth patches.\n",
        "- Foundation models separate representation learning from downstream tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. What Is an Embedding?\n",
        "\n",
        "A compact vector summarizing a patch: land cover, texture, temporal behavior, and context. Nearby vectors imply similar places.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Three Major EO Foundation Approaches\n",
        "\n",
        "- **Prithvi**: spatio-temporal masked modeling for Earth dynamics.\n",
        "- **AlphaEarth**: global semantic embeddings for every place.\n",
        "- **SatMAE**: masked autoencoding for spatial structure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Geometry of Embedding Space\n",
        "\n",
        "Distances encode semantic differences, clusters reveal land-use types, and directions can represent transitions (urbanization, deforestation).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Python — Embedding Demo (NumPy)\n",
        "\n",
        "`days/day28/code/embeddings_demo.py` creates toy embeddings and measures distances.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [
          "python"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prithvi: Spatio-temporal masked modeling | best for Time-series tasks\n",
            "AlphaEarth: Global EO embeddings | best for Fast transfer & search\n",
            "SatMAE: Masked autoencoding | best for Spatial representation learning\n",
            "Embedding distance: 0.13914865255355835\n"
          ]
        }
      ],
      "source": [
        "from days.day28.code.embeddings_demo import MODELS, embed_patch, embedding_distance\n",
        "import numpy as np\n",
        "\n",
        "for model in MODELS:\n",
        "    print(f\"{model.name}: {model.focus} | best for {model.best_for}\")\n",
        "\n",
        "rng = np.random.default_rng(0)\n",
        "patch_a = rng.random((16, 16, 4)).astype(np.float32)\n",
        "patch_b = patch_a.copy()\n",
        "patch_b[4:8, 6:10, :] += 0.4\n",
        "patch_b = np.clip(patch_b, 0, 1)\n",
        "\n",
        "emb_a = embed_patch(patch_a)\n",
        "emb_b = embed_patch(patch_b)\n",
        "print(\"Embedding distance:\", embedding_distance(emb_a, emb_b))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualization — Embedding Drift\n",
        "\n",
        "`days/day28/code/visualizations.py` plots embedding distance as change intensity increases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [
          "python"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set RUN_FIGURES = True to regenerate Day 28 figures inside days/day28/outputs/.\n"
          ]
        }
      ],
      "source": [
        "from days.day28.code.visualizations import plot_embedding_drift\n",
        "\n",
        "RUN_FIGURES = False\n",
        "\n",
        "if RUN_FIGURES:\n",
        "    plot_embedding_drift()\n",
        "else:\n",
        "    print(\"Set RUN_FIGURES = True to regenerate Day 28 figures inside days/day28/outputs/.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Embeddings in Practice\n",
        "\n",
        "- Classification: train a lightweight classifier on embeddings.\n",
        "- Clustering: group land-use types via KMeans/UMAP.\n",
        "- Change detection: threshold embedding distance over time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Advantages vs Raw Pixels\n",
        "\n",
        "| Aspect | Raw Pixels | Embeddings |\n",
        "| --- | --- | --- |\n",
        "| Dimensionality | Very high | Compact |\n",
        "| Labels needed | Many | Few |\n",
        "| Transfer | Low | High |\n",
        "| Robustness | Sensitive | Strong |\n",
        "| Compute | Heavy | Light |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Limitations & Cautions\n",
        "\n",
        "Embeddings are not magic: resolution can be fixed, interpretability is lower, and domain shift still matters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Mini Exercises\n",
        "\n",
        "1. Compare embeddings-only vs indices-only classification.\n",
        "2. Visualize embeddings with UMAP/t-SNE.\n",
        "3. Detect urban growth via embedding distance over years.\n",
        "4. Cluster embeddings and interpret clusters geographically.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Key Takeaways\n",
        "\n",
        "- Foundation models learn the grammar of Earth.\n",
        "- Embeddings store semantic meaning, not raw reflectance.\n",
        "- Prithvi, AlphaEarth, SatMAE target different strengths.\n",
        "- Embeddings enable fast, transferable downstream models.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
