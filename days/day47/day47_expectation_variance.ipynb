{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 47 — \"Expectation, Variance & Concentration: Why Averaging Works\"\n",
        "\n",
        "Averaging reduces noise. Expectation defines learning objectives, and variance quantifies stability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [
          "python"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using repo root: /media/abdul-aziz/sdb7/masters_research/math_course_dlcv\n"
          ]
        }
      ],
      "source": [
        "# Ensure repo root is on sys.path for local imports\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "repo_root = Path.cwd()\n",
        "if not (repo_root / \"days\").exists():\n",
        "    for parent in Path.cwd().resolve().parents:\n",
        "        if (parent / \"days\").exists():\n",
        "            repo_root = parent\n",
        "            break\n",
        "\n",
        "sys.path.insert(0, str(repo_root))\n",
        "print(f\"Using repo root: {repo_root}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Core Intuition\n",
        "\n",
        "Averages cancel randomness. This is why mini-batches, ensembles, and expectation-based losses work.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Expectation\n",
        "\n",
        "The expectation E[X] is the long-run average and the center of randomness.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Variance\n",
        "\n",
        "Variance measures spread. High variance means noisy gradients; low variance means stable training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Python — Variance of the Mean\n",
        "\n",
        "`days/day47/code/expectation_variance.py` estimates how variance shrinks with batch size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [
          "python"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Var(mean) for n= 1 : 0.9238648172801227\n",
            "Var(mean) for n= 5 : 0.19721419003603327\n",
            "Var(mean) for n= 20 : 0.05014173279320334\n",
            "Var(mean) for n= 100 : 0.011444976562763855\n",
            "Var(mean) for n= 500 : 0.0020319334329032155\n"
          ]
        }
      ],
      "source": [
        "from days.day47.code.expectation_variance import variance_of_mean\n",
        "\n",
        "for n in [1, 5, 20, 100, 500]:\n",
        "    print(\"Var(mean) for n=\", n, \":\", variance_of_mean(n))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualization — Variance Shrink\n",
        "\n",
        "`days/day47/code/visualizations.py` plots Var(mean) vs batch size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [
          "python"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set RUN_FIGURES = True to regenerate Day 47 figures inside days/day47/outputs/.\n"
          ]
        }
      ],
      "source": [
        "from days.day47.code.visualizations import plot_variance_shrink\n",
        "\n",
        "RUN_FIGURES = False\n",
        "\n",
        "if RUN_FIGURES:\n",
        "    plot_variance_shrink()\n",
        "else:\n",
        "    print(\"Set RUN_FIGURES = True to regenerate Day 47 figures inside days/day47/outputs/.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Key Takeaways\n",
        "\n",
        "- Expectation defines learning objectives.\n",
        "- Variance measures noise and instability.\n",
        "- Averaging reduces variance as 1/n.\n",
        "- Mini-batches balance noise and stability.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
