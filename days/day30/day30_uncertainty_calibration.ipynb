{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 30 — \"Uncertainty, Calibration & Decision-Making in EO Models\"\n",
        "\n",
        "Uncertainty tells you how much to trust a prediction. Calibration makes probabilities honest enough for policy-grade decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [
          "python"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using repo root: /media/abdul-aziz/sdb7/masters_research/math_course_dlcv\n"
          ]
        }
      ],
      "source": [
        "# Ensure repo root is on sys.path for local imports\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "repo_root = Path.cwd()\n",
        "if not (repo_root / \"days\").exists():\n",
        "    for parent in Path.cwd().resolve().parents:\n",
        "        if (parent / \"days\").exists():\n",
        "            repo_root = parent\n",
        "            break\n",
        "\n",
        "sys.path.insert(0, str(repo_root))\n",
        "print(f\"Using repo root: {repo_root}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Core Intuition\n",
        "\n",
        "- Accuracy answers: \"Was I right?\"\n",
        "- Uncertainty answers: \"How much should I trust this?\"\n",
        "- EO decisions need calibrated confidence, not just raw scores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Types of Uncertainty\n",
        "\n",
        "- **Aleatoric**: noise inherent to data (clouds, speckle).\n",
        "- **Epistemic**: model uncertainty (unseen regions, domain shift).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Predictive Uncertainty Methods\n",
        "\n",
        "- MC Dropout (easy, strong baseline)\n",
        "- Deep ensembles (strongest, but expensive)\n",
        "- Bayesian neural nets (advanced)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Calibration\n",
        "\n",
        "A calibrated model satisfies: among predictions at 0.7 confidence, about 70% are correct.\n",
        "Metrics like ECE quantify miscalibration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Python — MC Dropout + ECE\n",
        "\n",
        "`days/day30/code/uncertainty_calibration.py` simulates MC dropout and computes ECE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [
          "python"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uncertainty mean: 0.008502523008926028\n",
            "ECE: 0.29900481789464434\n"
          ]
        }
      ],
      "source": [
        "from days.day30.code.uncertainty_calibration import mc_dropout_predict, ece\n",
        "import numpy as np\n",
        "\n",
        "rng = np.random.default_rng(1)\n",
        "logits = rng.normal(0, 1.2, size=(64, 64))\n",
        "labels = (rng.random((64, 64)) > 0.8).astype(np.float32)\n",
        "\n",
        "mean_pred, var_pred = mc_dropout_predict(logits)\n",
        "print(\"Uncertainty mean:\", var_pred.mean())\n",
        "print(\"ECE:\", ece(mean_pred.flatten(), labels.flatten()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualization — Reliability + Uncertainty Maps\n",
        "\n",
        "`days/day30/code/visualizations.py` draws a reliability diagram and an uncertainty map.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [
          "python"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set RUN_FIGURES = True to regenerate Day 30 figures inside days/day30/outputs/.\n"
          ]
        }
      ],
      "source": [
        "from days.day30.code.visualizations import plot_reliability_diagram, plot_uncertainty_map\n",
        "\n",
        "RUN_FIGURES = False\n",
        "\n",
        "if RUN_FIGURES:\n",
        "    plot_reliability_diagram()\n",
        "    plot_uncertainty_map()\n",
        "else:\n",
        "    print(\"Set RUN_FIGURES = True to regenerate Day 30 figures inside days/day30/outputs/.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Decision Rules\n",
        "\n",
        "Combine confidence and uncertainty, for example:\n",
        "\n",
        "`decision = (mean > 0.7) & (variance < 0.05)`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. EO-Specific Use Cases\n",
        "\n",
        "- Flood mapping: high recall + uncertainty-aware warnings.\n",
        "- Change detection: ignore high-uncertainty seasonal pixels.\n",
        "- Land-use mapping: flag uncertain parcels for review.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Common Mistakes\n",
        "\n",
        "- Trusting raw probabilities.\n",
        "- Ignoring distribution shift.\n",
        "- Hiding uncertainty from users.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Mini Exercises\n",
        "\n",
        "1. Compare calibrated vs uncalibrated ECE.\n",
        "2. Apply uncertainty thresholding to reduce false positives.\n",
        "3. Visualize uncertainty over cloudy regions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Key Takeaways\n",
        "\n",
        "- Uncertainty distinguishes guesses from knowledge.\n",
        "- Calibration makes probabilities meaningful.\n",
        "- EO decisions should incorporate risk and confidence.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
